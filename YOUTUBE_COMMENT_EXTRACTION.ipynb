{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65321549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (2.103.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-python-client) (2.23.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-python-client) (2.12.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-python-client) (0.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.24.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\onedrive\\documents\\new folder\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe3aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super song guruüí•üí•\n",
      "Ghost üéâ\n",
      "Hukum tiger ka hukum\n",
      "Big Grand daddy\n",
      "üéâüéâüéâ fire\n",
      "We want tamil version.... pleaseüõêüõê\n",
      "Lyrics matra superbüî•üî•\n",
      "Yavanadru fan made song antana guru idanna? Much better than so called movie songs.Imagine budget enadru jaasti idre antuüî•üî• great work.\n",
      "Ill be first in line for that movie!\n",
      "Ghosts music is a gift to us all.\n",
      "Cant wait to see this anthem in the movie.\n",
      "This song is pure magic.\n",
      "Ghost knows how to tug at our heartstrings.\n",
      "Ghost has created something truly special with this fanthem.\n",
      "This fanthem will be in my playlist for a lifetime.\n",
      "Im already picking out the best seat at the theater.\n",
      "A fanthem that gives me goosebumps every time.\n",
      "Im on the edge of my seat for the big release.\n",
      "Movie night with this fanthem is a must.\n",
      "Im already planning my second viewing.\n",
      "Im already playing the trailer on repeat.\n",
      "Ive got my ticket ready for opening night.\n",
      "The anticipation for this film is palpable.\n",
      "This movie is pure cinematic brilliance.\n",
      "Im eagerly awaiting the release date.\n",
      "Ghost, youve captured my heart and soul with your storytelling prowess.\n",
      "This trailer is an absolute visual triumph.\n",
      "Im already playing the trailer on repeat.\n",
      "Im addicted to the emotions it stirs.\n",
      "Unforgettable, just like Ghost themselves.\n",
      "The buzz around this movie is truly exhilarating.\n",
      "Im prepared to be swept away by the cinematic masterpiece.\n",
      "Ghost movie holds a special place in my heart.\n",
      "Im completely hooked on this movies allure.\n",
      "A haunting anthem thats impossible to forget.\n",
      "This trailer is a masterpiece in the making.\n",
      "The trailer gives me chills every time.\n",
      "The excitement for this film is palpable, and I love it.\n",
      "Ghosts fanthem is a treasure.\n",
      "Im completely captivated by this trailer.\n",
      "Ghost, youve tugged at my heartstrings profoundly.\n",
      "Im addicted to the anticipation.\n",
      "This movie is bound to be an unforgettable cinematic experience.\n",
      "Im already planning a cozy movie night!\n",
      "Ghost movie is pure cinematic magic.\n",
      "Ghost, youve captured my heart.\n",
      "This song is pure magic.\n",
      "Cant wait to see this anthem in the movie.\n",
      "Ghost movie, youve won my heart.\n",
      "This film is destined to become a classic.\n",
      "Ghost, youve won my heart with your story.\n",
      "Ghosts music is a gift to us all.\n",
      "The trailer is an emotional rollercoaster.\n",
      "Ghosts fanthem is a work of art.\n",
      "Ghost, youve created a masterpiece that resonates.\n",
      "This trailer is a breathtaking cinematic spectacle.\n",
      "This trailer is a breathtaking cinematic spectacle.\n",
      "Ghost, youve created something truly special.\n",
      "Im ready for this epic cinematic adventure to begin.\n",
      "This anthem deserves all the praise.\n",
      "Speechless in the presence of such an anthem.\n",
      "This trailer is a visual symphony of storytelling.\n",
      "Im already planning my second viewing.\n",
      "Im already picking out my movie-watching snacks.\n",
      "Im counting down to the premiere!\n",
      "Ghost has truly outdone themselves with this anthem.\n",
      "This trailer is movie-making at its finest.\n",
      "Im already planning a cozy movie night with friends.\n",
      "Ghost has me eagerly waiting for its release.\n",
      "Im in awe of Ghosts creativity.\n",
      "Im ready for this epic cinematic journey.\n",
      "Ghosts music is pure magic.\n",
      "Im counting down to the epic premiere!\n",
      "Movie popcorn ready, and Im excited!\n",
      "The buzz surrounding this film is electrifying, and I cant get enough.\n",
      "The excitement for this movie is infectious.\n",
      "Im ready to be swept away by this cinematic journey.\n",
      "Im already choosing my favorite movie-watching snacks.\n",
      "The anticipation is driving me crazy!\n",
      "The trailer is a true visual feast for the eyes.\n",
      "Ghost movie, you have my heart.\n",
      "Im already lost in the world of Ghost.\n",
      "Ghosts fanthem is a masterpiece.\n",
      "This movie is going to be iconic.\n",
      "This film is going to be iconic.\n",
      "Ghost, youve created a masterpiece for the ages.\n",
      "Ghost has created a masterpiece.\n",
      "The excitement for this film is reaching a crescendo.\n",
      "Im already planning the perfect cinematic viewing experience.\n",
      "This trailer is an emotional journey.\n",
      "Im addicted to the excitement.\n",
      "Ghosts fanthem is pure perfection.\n",
      "Im counting down the seconds to the premiere!\n",
      "This anthem is an emotional journey.\n",
      "Ghosts talent knows no bounds.\n",
      "Im addicted to the emotions and thrills it promises to deliver.\n",
      "Im gearing up for the emotional ride of this movie.\n",
      "The trailer is pure visual poetry.\n",
      "The movie promises to be an unforgettable experience.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fa10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: motive guard\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T17:07:54Z\n",
      "---\n",
      "Username: Shiva kumar Shivu\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T15:47:36Z\n",
      "---\n",
      "Username: ROHITH P\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T15:38:35Z\n",
      "---\n",
      "Username: Abhay Naik\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T15:38:14Z\n",
      "---\n",
      "Username: KA VIDEO'S\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T12:40:08Z\n",
      "---\n",
      "Username: Kamesh A\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T12:00:39Z\n",
      "---\n",
      "Username: Chandan Gundlupete\n",
      "Likes: 1\n",
      "Comment Date: 2023-10-13T10:57:16Z\n",
      "---\n",
      "Username: Tech Geek\n",
      "Likes: 15\n",
      "Comment Date: 2023-10-13T09:16:20Z\n",
      "---\n",
      "Username: MEG  LADOR FF\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:54Z\n",
      "---\n",
      "Username: ÿ∂ÿ±ÿßÿ± ÿßŸÑÿÆÿ∑Ÿäÿ®\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:54Z\n",
      "---\n",
      "Username: japa vision\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:41Z\n",
      "---\n",
      "Username: Serba Serbi Kehidupan\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:40Z\n",
      "---\n",
      "Username: Game memes \n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:27Z\n",
      "---\n",
      "Username: TÃæEÃæCÃæHÃæNÃæIÃæCÃæAÃæLÃæ gÃæAmInG\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:13:27Z\n",
      "---\n",
      "Username: Inshila Yamumana\n",
      "Likes: 5\n",
      "Comment Date: 2023-10-13T09:13:27Z\n",
      "---\n",
      "Username: yalla nebd2\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:11:06Z\n",
      "---\n",
      "Username: Polito de lima\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:59Z\n",
      "---\n",
      "Username: ellosdaOMG\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:58Z\n",
      "---\n",
      "Username: Si mas kakang\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:51Z\n",
      "---\n",
      "Username: TechSpeaker\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:49Z\n",
      "---\n",
      "Username: D.L KAMINA GAMING\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:43Z\n",
      "---\n",
      "Username: Berff\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:43Z\n",
      "---\n",
      "Username: terminator10\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:43Z\n",
      "---\n",
      "Username: Waqar Baadshah\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:40Z\n",
      "---\n",
      "Username: MayOneDay\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:35Z\n",
      "---\n",
      "Username: Mikayil √úsmen\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:35Z\n",
      "---\n",
      "Username: XREX PS\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:35Z\n",
      "---\n",
      "Username: –®—É—Ç\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:35Z\n",
      "---\n",
      "Username: SUPER CHRISTIAN TUBE ·à±·çê·à≠ ·ä≠·à≠·àµ·â≤·ã´·äï ·â±·â•\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:33Z\n",
      "---\n",
      "Username: Pushpa Teaser\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:33Z\n",
      "---\n",
      "Username: pintu 2\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:33Z\n",
      "---\n",
      "Username: ·éª…™·¥õ ü·¥á ÄBoss Boss\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:33Z\n",
      "---\n",
      "Username: Juan Pratama\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:31Z\n",
      "---\n",
      "Username: Kyla Optik\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:29Z\n",
      "---\n",
      "Username: dorikk\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:29Z\n",
      "---\n",
      "Username: Aryan Jaryal Vlogs\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:27Z\n",
      "---\n",
      "Username: Md Carrom Star\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:27Z\n",
      "---\n",
      "Username: Mohamd Iqbal\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:27Z\n",
      "---\n",
      "Username: TimmyVFX\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:25Z\n",
      "---\n",
      "Username: mariana‚ô°\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:25Z\n",
      "---\n",
      "Username: Alaa cuisine\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:25Z\n",
      "---\n",
      "Username: ŸÖÿ≠ŸÖÿØ ÿßÿ≠ŸÖÿØ\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:25Z\n",
      "---\n",
      "Username: El PAiiSA Feo Es Feo\n",
      "Likes: 1\n",
      "Comment Date: 2023-10-13T09:10:23Z\n",
      "---\n",
      "Username: efd\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:22Z\n",
      "---\n",
      "Username: Super channel\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:22Z\n",
      "---\n",
      "Username: S P\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:22Z\n",
      "---\n",
      "Username: Trikzy1k\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:19Z\n",
      "---\n",
      "Username: ipowergigi xD\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:17Z\n",
      "---\n",
      "Username: 1·¥ã\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:17Z\n",
      "---\n",
      "Username: P-BLOKE SOUND\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:15Z\n",
      "---\n",
      "Username: Shorts\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:15Z\n",
      "---\n",
      "Username: FF FLIX\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:15Z\n",
      "---\n",
      "Username: RoyaL.\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:13Z\n",
      "---\n",
      "Username: Saleh Ghaze\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: thatkidd bri\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: pandus\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: Brayan Bortolotti\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: Anastasia\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: Play it Boy\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: …¥·¥è·¥è ô ·¥ç·¥Äs·¥õ·¥á Ä\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: Phan H∆∞ng 2002\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:12Z\n",
      "---\n",
      "Username: Awqzzz\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:11Z\n",
      "---\n",
      "Username: Viral Fun\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:10Z\n",
      "---\n",
      "Username: Roberto _Panam√°\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:10Z\n",
      "---\n",
      "Username: Za Se\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:09Z\n",
      "---\n",
      "Username: Melati jingga\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:09Z\n",
      "---\n",
      "Username: Game Mod Hot\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:08Z\n",
      "---\n",
      "Username: Tik Tok 2019\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:08Z\n",
      "---\n",
      "Username: Nova Gaming\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:08Z\n",
      "---\n",
      "Username: HAS# TUBER\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:06Z\n",
      "---\n",
      "Username: SHOURYA KASHYAP\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:06Z\n",
      "---\n",
      "Username: E Fangirl\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:06Z\n",
      "---\n",
      "Username: Lizy Santana\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:06Z\n",
      "---\n",
      "Username: 4·¥ã·≠Ñ ·¥ç ·¥ú Íú± …™ ·¥Ñ\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:05Z\n",
      "---\n",
      "Username: Parrot World\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: VickVidea\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: PREDIKSI TOTOMACAU\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: Cowok2\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: TheRealWorld\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: Orange950\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: ElMundo Freestyle\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: Romeo Vlogs\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: dais thkir\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: Painite_Sound\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: Govend games\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:04Z\n",
      "---\n",
      "Username: khoadz\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:01Z\n",
      "---\n",
      "Username: Baby Kareem\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:01Z\n",
      "---\n",
      "Username: A.N Info Tech\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:01Z\n",
      "---\n",
      "Username: JustME STORE\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:00Z\n",
      "---\n",
      "Username: Nh·∫≠t Vlog\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:00Z\n",
      "---\n",
      "Username: Biblia Detalhada\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:10:00Z\n",
      "---\n",
      "Username: Jasiel\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:59Z\n",
      "---\n",
      "Username: Contacte\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:59Z\n",
      "---\n",
      "Username: Luis\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:59Z\n",
      "---\n",
      "Username: Minsungbabies\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:57Z\n",
      "---\n",
      "Username: Leandro Garcia\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:57Z\n",
      "---\n",
      "Username: momo Vlogs paris\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:57Z\n",
      "---\n",
      "Username: CHENEL 1\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:57Z\n",
      "---\n",
      "Username: Smiling Shorts\n",
      "Likes: 0\n",
      "Comment Date: 2023-10-13T09:09:57Z\n",
      "---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2affd18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Username  Likes          Comment Date\n",
      "0        motive guard      0  2023-10-13T17:07:54Z\n",
      "1   Shiva kumar Shivu      0  2023-10-13T15:47:36Z\n",
      "2            ROHITH P      0  2023-10-13T15:38:35Z\n",
      "3          Abhay Naik      0  2023-10-13T15:38:14Z\n",
      "4          KA VIDEO'S      0  2023-10-13T12:40:08Z\n",
      "..                ...    ...                   ...\n",
      "94      Minsungbabies      0  2023-10-13T09:09:57Z\n",
      "95     Leandro Garcia      0  2023-10-13T09:09:57Z\n",
      "96   momo Vlogs paris      0  2023-10-13T09:09:57Z\n",
      "97           CHENEL 1      0  2023-10-13T09:09:57Z\n",
      "98     Smiling Shorts      0  2023-10-13T09:09:57Z\n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id = 'ducaEN3rKjU'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "dislike_counts = []\n",
    "comment_dates = []\n",
    "\n",
    "# Get the comments for the video\n",
    "try:\n",
    "    comments = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        textFormat='plainText',\n",
    "        maxResults=100  # You can adjust the number of comments to fetch\n",
    "    ).execute()\n",
    "\n",
    "    for comment in comments['items']:\n",
    "        username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "        like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "        \n",
    "        comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "        \n",
    "        usernames.append(username)\n",
    "        like_counts.append(like_count)\n",
    "        \n",
    "        comment_dates.append(comment_date)\n",
    "\n",
    "except HttpError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Likes': like_counts,\n",
    "    \n",
    "    'Comment Date': comment_dates\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684847dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Username  \\\n",
      "0        motive guard   \n",
      "1   Shiva kumar Shivu   \n",
      "2            ROHITH P   \n",
      "3          Abhay Naik   \n",
      "4          KA VIDEO'S   \n",
      "..                ...   \n",
      "94      Minsungbabies   \n",
      "95     Leandro Garcia   \n",
      "96   momo Vlogs paris   \n",
      "97           CHENEL 1   \n",
      "98     Smiling Shorts   \n",
      "\n",
      "                                                            Comment  Likes  \\\n",
      "0                                                 Super song guruüí•üí•      0   \n",
      "1                                                           Ghost üéâ      0   \n",
      "2                                              Hukum tiger ka hukum      0   \n",
      "3                                                   Big Grand daddy      0   \n",
      "4                                                          üéâüéâüéâ fire      0   \n",
      "..                                                              ...    ...   \n",
      "94                                   Ghosts talent knows no bounds.      0   \n",
      "95  Im addicted to the emotions and thrills it promises to deliver.      0   \n",
      "96              Im gearing up for the emotional ride of this movie.      0   \n",
      "97                               The trailer is pure visual poetry.      0   \n",
      "98            The movie promises to be an unforgettable experience.      0   \n",
      "\n",
      "            Comment Date  \n",
      "0   2023-10-13T17:07:54Z  \n",
      "1   2023-10-13T15:47:36Z  \n",
      "2   2023-10-13T15:38:35Z  \n",
      "3   2023-10-13T15:38:14Z  \n",
      "4   2023-10-13T12:40:08Z  \n",
      "..                   ...  \n",
      "94  2023-10-13T09:09:57Z  \n",
      "95  2023-10-13T09:09:57Z  \n",
      "96  2023-10-13T09:09:57Z  \n",
      "97  2023-10-13T09:09:57Z  \n",
      "98  2023-10-13T09:09:57Z  \n",
      "\n",
      "[99 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id = 'ducaEN3rKjU'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "dislike_counts = []\n",
    "comment_dates = []\n",
    "comments = []\n",
    "\n",
    "# Get the comments for the video\n",
    "try:\n",
    "    comments_data = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        textFormat='plainText',\n",
    "        maxResults=100  # You can adjust the number of comments to fetch\n",
    "    ).execute()\n",
    "\n",
    "    for comment in comments_data['items']:\n",
    "        username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "        like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "        comment_text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "        \n",
    "\n",
    "        usernames.append(username)\n",
    "        like_counts.append(like_count)\n",
    "        comments.append(comment_text)\n",
    "        comment_dates.append(comment_date)\n",
    "        \n",
    "\n",
    "except HttpError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Comment': comments,\n",
    "    'Likes': like_counts,\n",
    "    'Comment Date': comment_dates,\n",
    "    \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "with pd.option_context('display.max_colwidth', None):  # Display full comment text\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d1e5b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Username  Likes          Comment Date               Comment\n",
      "0            motive guard      0  2023-10-13T17:07:54Z     Super song guruüí•üí•\n",
      "1       Shiva kumar Shivu      0  2023-10-13T15:47:36Z               Ghost üéâ\n",
      "2                ROHITH P      0  2023-10-13T15:38:35Z  Hukum tiger ka hukum\n",
      "3              Abhay Naik      0  2023-10-13T15:38:14Z       Big Grand daddy\n",
      "4              KA VIDEO'S      0  2023-10-13T12:40:08Z              üéâüéâüéâ fire\n",
      "...                   ...    ...                   ...                   ...\n",
      "2603              Motu HC      6  2023-10-11T12:56:14Z                 Boss‚ù§\n",
      "2604  Mahamadriyaz Kodgli      3  2023-10-11T12:54:26Z       ‡≤∂‡≤ø‡≤µ‡≤£‡≥ç‡≤£ ‡≤¨‡≤æ‡≤∏‡≥ç‚ù§Ô∏è‚ù§Ô∏è\n",
      "2605  Mahamadriyaz Kodgli      2  2023-10-11T12:53:54Z         ‡≤∂‡≤ø‡≤µ‡≤£‡≥ç‡≤£ ‡≤¨‡≤æ‡≤∏‡≥ç‚ù§Ô∏è\n",
      "2606       SRUJAN KUMAR R      2  2023-10-11T12:53:44Z                    Hi\n",
      "2607  Mahamadriyaz Kodgli      4  2023-10-11T12:53:01Z                    ‚ù§Ô∏è\n",
      "\n",
      "[2608 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id = 'ducaEN3rKjU'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "dislike_counts = []\n",
    "comment_dates = []\n",
    "comments = []\n",
    "\n",
    "next_page_token = None  # For pagination\n",
    "\n",
    "# Loop to retrieve all comments (multiple API requests might be needed)\n",
    "while True:\n",
    "    try:\n",
    "        comments_data = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            textFormat='plainText',\n",
    "            maxResults=100,  # You can adjust the number of comments to fetch\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for comment in comments_data['items']:\n",
    "            username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "            \n",
    "            comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            usernames.append(username)\n",
    "            like_counts.append(like_count)\n",
    "            \n",
    "            comment_dates.append(comment_date)\n",
    "            comments.append(comment_text)\n",
    "\n",
    "        if 'nextPageToken' in comments_data:\n",
    "            next_page_token = comments_data['nextPageToken']\n",
    "        else:\n",
    "            break  # No more comments to retrieve\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Likes': like_counts,\n",
    "    \n",
    "    'Comment Date': comment_dates,\n",
    "    'Comment': comments\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "with pd.option_context('display.max_colwidth', None):  # Display full comment text\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b953c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Username  Likes          Comment Date  \\\n",
      "0        Legend Of Zodiac      0  2023-10-14T03:31:12Z   \n",
      "1                  üçÉ‡Æâ‡Æ§‡ÆØ‡ÆæüçÉ      0  2023-10-14T03:26:08Z   \n",
      "2        sathish selvaraj      0  2023-10-14T03:19:25Z   \n",
      "3       Manoj tp Manoj tp      0  2023-10-14T03:15:08Z   \n",
      "4          Adarsh Prakash      0  2023-10-14T03:10:43Z   \n",
      "...                   ...    ...                   ...   \n",
      "2612              Motu HC      6  2023-10-11T12:56:14Z   \n",
      "2613  Mahamadriyaz Kodgli      3  2023-10-11T12:54:26Z   \n",
      "2614  Mahamadriyaz Kodgli      2  2023-10-11T12:53:54Z   \n",
      "2615       SRUJAN KUMAR R      2  2023-10-11T12:53:44Z   \n",
      "2616  Mahamadriyaz Kodgli      4  2023-10-11T12:53:01Z   \n",
      "\n",
      "                      Comment  \n",
      "0        Alappara Kelapurom üòÖ  \n",
      "1             Copy song üòÇüòÇüòÇüòÇüòÇ  \n",
      "2     Music like jalier theme  \n",
      "3                       üòÆüòÆüòÆüòÆüòÆ  \n",
      "4                      Srk ‚ù§Ô∏è  \n",
      "...                       ...  \n",
      "2612                    Boss‚ù§  \n",
      "2613          ‡≤∂‡≤ø‡≤µ‡≤£‡≥ç‡≤£ ‡≤¨‡≤æ‡≤∏‡≥ç‚ù§Ô∏è‚ù§Ô∏è  \n",
      "2614            ‡≤∂‡≤ø‡≤µ‡≤£‡≥ç‡≤£ ‡≤¨‡≤æ‡≤∏‡≥ç‚ù§Ô∏è  \n",
      "2615                       Hi  \n",
      "2616                       ‚ù§Ô∏è  \n",
      "\n",
      "[2617 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id = 'ducaEN3rKjU'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "dislike_counts = []\n",
    "comment_dates = []\n",
    "comments = []\n",
    "\n",
    "next_page_token = None  # For pagination\n",
    "\n",
    "# Loop to retrieve all comments (multiple API requests might be needed)\n",
    "while True:\n",
    "    try:\n",
    "        comments_data = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            textFormat='plainText',\n",
    "            maxResults=100,  # You can adjust the number of comments to fetch\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for comment in comments_data['items']:\n",
    "            username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "            \n",
    "            comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            usernames.append(username)\n",
    "            like_counts.append(like_count)\n",
    "            \n",
    "            comment_dates.append(comment_date)\n",
    "            comments.append(comment_text)\n",
    "\n",
    "        if 'nextPageToken' in comments_data:\n",
    "            next_page_token = comments_data['nextPageToken']\n",
    "        else:\n",
    "            break  # No more comments to retrieve\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Likes': like_counts,\n",
    "    \n",
    "    'Comment Date': comment_dates,\n",
    "    'Comment': comments\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "with pd.option_context('display.max_colwidth', None):  # Display full comment text\n",
    "    print(df)\n",
    "df.to_excel('youtube_comments.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f41838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\minor_project'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25064a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id = 'haqi4xvjvKo'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "dislike_counts = []\n",
    "comment_dates = []\n",
    "comments = []\n",
    "\n",
    "next_page_token = None  # For pagination\n",
    "\n",
    "# Loop to retrieve all comments (multiple API requests might be needed)\n",
    "while True:\n",
    "    try:\n",
    "        comments_data = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            textFormat='plainText',\n",
    "            maxResults=100,  # You can adjust the number of comments to fetch\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for comment in comments_data['items']:\n",
    "            username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "            \n",
    "            comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            usernames.append(username)\n",
    "            like_counts.append(like_count)\n",
    "            \n",
    "            comment_dates.append(comment_date)\n",
    "            comments.append(comment_text)\n",
    "\n",
    "        if 'nextPageToken' in comments_data:\n",
    "            next_page_token = comments_data['nextPageToken']\n",
    "        else:\n",
    "            break  # No more comments to retrieve\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Likes': like_counts,\n",
    "    \n",
    "    'Comment Date': comment_dates,\n",
    "    'Comment': comments\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('youtube_comments.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4520ea21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=CyjwcM6Jd0k%26t&textFormat=plainText&maxResults=100&key=AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "Empty DataFrame\n",
      "Columns: [Username, Likes, Comment Date, Comment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "\n",
    "# Set your API key\n",
    "api_key = 'AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous'\n",
    "\n",
    "# Create a YouTube Data API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Video ID of the video with comments you want to extract\n",
    "video_id ='CyjwcM6Jd0k&t'\n",
    "\n",
    "# Create empty lists to store data\n",
    "usernames = []\n",
    "like_counts = []\n",
    "comment_dates = []\n",
    "comments = []  # Initialize as an empty list\n",
    "locations = []  # Location information if available\n",
    "\n",
    "next_page_token = None  # For pagination\n",
    "\n",
    "# Loop to retrieve all comments (multiple API requests might be needed)\n",
    "while True:\n",
    "    try:\n",
    "        comments_data = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            textFormat='plainText',\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for comment in comments_data['items']:\n",
    "            username = comment['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "            like_count = comment['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "            comment_date = comment['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "            comment_text = comment['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            # Try to get location information if available\n",
    "            try:\n",
    "                location = comment['snippet']['topLevelComment']['snippet']['location']\n",
    "            except KeyError:\n",
    "                location = 'N/A'\n",
    "\n",
    "            usernames.append(username)\n",
    "            like_counts.append(like_count)\n",
    "            comment_dates.append(comment_date)\n",
    "            comments.append(comment_text)  # Append the comment text here\n",
    "        \n",
    "\n",
    "        if 'nextPageToken' in comments_data:\n",
    "            next_page_token = comments_data['nextPageToken']\n",
    "        else:\n",
    "            break  # No more comments to retrieve\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Likes': like_counts,\n",
    "    'Comment Date': comment_dates,\n",
    "    'Comment': comments,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "with pd.option_context('display.max_colwidth', None):  # Display full comment text\n",
    "    print(df)\n",
    "df.to_excel('youtube_comments.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fd9798",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2094716047.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25492\\2094716047.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install pytube\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install pytube\n",
    "pip install re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3c0241",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D_h4Q51iGDyU&maxResults=100&pageToken=&key=AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9384\\3253467310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Retrieve all comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mall_comments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_all_comments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Create a DataFrame from the comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9384\\3253467310.py\u001b[0m in \u001b[0;36mretrieve_all_comments\u001b[1;34m(video_id)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         results = youtube.commentThreads().list(\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mpart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"snippet\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mvideoId\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\New folder\\lib\\site-packages\\googleapiclient\\_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\New folder\\lib\\site-packages\\googleapiclient\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D_h4Q51iGDyU&maxResults=100&pageToken=&key=AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your API credentials\n",
    "api_key = \"AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous\"\n",
    "\n",
    "# Create a service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "# Video ID for the YouTube video\n",
    "video_id = \"https://www.youtube.com/watch?v=_h4Q51iGDyU\"\n",
    "\n",
    "# Function to retrieve all comments\n",
    "def retrieve_all_comments(video_id):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        results = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,  # You can adjust the number of results per request\n",
    "            pageToken=next_page_token if next_page_token else \"\"\n",
    "        ).execute()\n",
    "\n",
    "        for item in results.get(\"items\", []):\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"Username\": comment[\"authorDisplayName\"],\n",
    "                \"Comment Date\": comment[\"publishedAt\"],\n",
    "                \"Comment\": comment[\"textDisplay\"],\n",
    "                \"Likes\": comment[\"likeCount\"]\n",
    "            })\n",
    "\n",
    "        next_page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Retrieve all comments\n",
    "all_comments = retrieve_all_comments(video_id)\n",
    "\n",
    "# Create a DataFrame from the comments\n",
    "comments_df = pd.DataFrame(all_comments)\n",
    "\n",
    "comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c94c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to an Excel file\n",
    "excel_writer = pd.ExcelWriter(\"youtube_comments.xlsx\", engine=\"openpyxl\")\n",
    "comments_df.to_excel(excel_writer, sheet_name=\"Comments\", index=False)\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce0b8f",
   "metadata": {},
   "source": [
    "# youtube shorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1322bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your API credentials\n",
    "api_key = \"AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous\"\n",
    "\n",
    "# Create a service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "# Video ID for the YouTube video (including YouTube Shorts)\n",
    "video_id = \"_pBiEum28EU\"\n",
    "\n",
    "# Function to retrieve all comments\n",
    "def retrieve_all_comments(video_id):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        results = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,  # You can adjust the number of results per request\n",
    "            pageToken=next_page_token if next_page_token else \"\"\n",
    "        ).execute()\n",
    "\n",
    "        for item in results.get(\"items\", []):\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"Username\": comment[\"authorDisplayName\"],\n",
    "                \"Comment Date\": comment[\"publishedAt\"],\n",
    "                \"Comment\": comment[\"textDisplay\"],\n",
    "                \"Likes\": comment[\"likeCount\"]\n",
    "            })\n",
    "\n",
    "        next_page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Retrieve all comments\n",
    "all_comments = retrieve_all_comments(video_id)\n",
    "\n",
    "# Create a DataFrame from the comments\n",
    "comments_df = pd.DataFrame(all_comments)\n",
    "\n",
    "comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dab270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to an Excel file\n",
    "excel_writer = pd.ExcelWriter(\"youtube_comments_3rd.xlsx\", engine=\"openpyxl\")\n",
    "comments_df.to_excel(excel_writer, sheet_name=\"Comments\", index=False)\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8716b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your API credentials\n",
    "api_key = \"AIzaSyB-wavsGsS_1Nekw2zux_2Gmlugop6Uous\"\n",
    "\n",
    "# Create a service\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "# List of video IDs for the YouTube videos\n",
    "video_ids = [\"xf_lzRVAh9E\",\"IGbl4qveGx4\",\"Nv0NCgfsbf8\",\"975_vWQA5B4\",\"Ne2uJwIJbEs\",\"arVEtDUkFGc\",\"uriMHeuhT9o\",\"8g2vd7Nb2ck\",\"1if3-UViv6I\",\"8pvQ3qxyoj0\",\"xuJBV9CjIDc\"]\n",
    "\n",
    "# Function to retrieve comments for a video\n",
    "def retrieve_comments(video_id):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        results = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=10000000,  # You can adjust the number of results per request\n",
    "            pageToken=next_page_token if next_page_token else \"\"\n",
    "        ).execute()\n",
    "\n",
    "        for item in results.get(\"items\", []):\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            comments.append({\n",
    "                \"Username\": comment[\"authorDisplayName\"],\n",
    "                \"Comment Date\": comment[\"publishedAt\"],\n",
    "                \"Comment\": comment[\"textDisplay\"],\n",
    "                \"Likes\": comment[\"likeCount\"]\n",
    "            })\n",
    "\n",
    "        next_page_token = results.get(\"nextPageToken\")\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade343de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video IDs for the YouTube videos\n",
    "video_ids = [\"xf_lzRVAh9E\",\"IGbl4qveGx4\",\"Nv0NCgfsbf8\",\"975_vWQA5B4\",\"Ne2uJwIJbEs\",\"arVEtDUkFGc\",\"uriMHeuhT9o\",\"8g2vd7Nb2ck\",\"1if3-UViv6I\",\"8pvQ3qxyoj0\",\"xuJBV9CjIDc\"]  # Add your video IDs here\n",
    "\n",
    "# Create an ExcelWriter object\n",
    "with pd.ExcelWriter(\"comments_data_05.xlsx\") as writer:\n",
    "    # Loop through each video ID, retrieve comments, and save to Excel sheets\n",
    "    for video_id in video_ids:\n",
    "        video_comments = retrieve_comments(video_id)\n",
    "        comments_df = pd.DataFrame(video_comments)\n",
    "        comments_df.to_excel(writer, sheet_name=f\"Video_{video_id}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eee6b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each video ID, retrieve comments, and save to Excel sheets\n",
    "for video_id in video_ids:\n",
    "    video_comments = retrieve_comments(video_id)\n",
    "    comments_df = pd.DataFrame(video_comments)\n",
    "    comments_df.to_excel(f\"{video_id}_comments.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
